{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification Training\n",
        "\n",
        "This notebook trains a CNN model for image classification using TensorFlow/Keras.\n",
        "\n",
        "## Setup\n",
        "First, let's import the necessary libraries and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Load images from the data/images directory. Make sure your images are organized in subdirectories by class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_images_from_directory(directory_path, img_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Load images from subdirectories and return X (images) and y (labels)\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = []\n",
        "    \n",
        "    # Get all subdirectories (classes)\n",
        "    subdirs = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
        "    subdirs.sort()  # Sort for consistent ordering\n",
        "    \n",
        "    print(f\"Found {len(subdirs)} classes: {subdirs}\")\n",
        "    \n",
        "    for class_idx, class_name in enumerate(subdirs):\n",
        "        class_names.append(class_name)\n",
        "        class_path = os.path.join(directory_path, class_name)\n",
        "        \n",
        "        # Get all image files in this class directory\n",
        "        image_files = glob.glob(os.path.join(class_path, \"*.jpg\")) + \\\n",
        "                     glob.glob(os.path.join(class_path, \"*.jpeg\")) + \\\n",
        "                     glob.glob(os.path.join(class_path, \"*.png\"))\n",
        "        \n",
        "        print(f\"Loading {len(image_files)} images from class '{class_name}'\")\n",
        "        \n",
        "        for image_file in image_files:\n",
        "            try:\n",
        "                # Load and preprocess image\n",
        "                img = Image.open(image_file)\n",
        "                img = img.convert('RGB')  # Convert to RGB\n",
        "                img = img.resize(img_size)  # Resize to target size\n",
        "                img_array = np.array(img) / 255.0  # Normalize to [0,1]\n",
        "                \n",
        "                images.append(img_array)\n",
        "                labels.append(class_idx)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {image_file}: {e}\")\n",
        "    \n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "# Load the data\n",
        "data_path = 'data/images'\n",
        "X, y, class_names = load_images_from_directory(data_path)\n",
        "\n",
        "print(f\"\\nDataset shape: {X.shape}\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "print(f\"Class names: {class_names}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Unique labels: {np.unique(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "num_classes = len(class_names)\n",
        "y_train_categorical = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_categorical = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(f\"Training labels shape: {y_train_categorical.shape}\")\n",
        "print(f\"Test labels shape: {y_test_categorical.shape}\")\n",
        "\n",
        "# Display some sample images\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(X_train[i])\n",
        "    plt.title(f\"Class: {class_names[y_train[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "Create a CNN model for image classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Create a CNN model for image classification\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        # First convolutional block\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Second convolutional block\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Third convolutional block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Fourth convolutional block\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        \n",
        "        # Flatten and dense layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "input_shape = X_train.shape[1:]  # (224, 224, 3)\n",
        "model = create_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
